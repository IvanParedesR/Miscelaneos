{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db630f44-d721-4717-bf88-1dd899430eb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Docker run instructions\n",
    "#Ve al repo en tu local con la terminal y corre el siguiente código.\n",
    "#docker run -it --rm -p 8888:8888 -v \"${PWD}\":/home/jovyan/work docker.io/jupyter/pyspark-notebook:latest\n",
    "\n",
    "from pyspark.sql.types import StructType, StructField, StringType, FloatType, IntegerType, BooleanType, ArrayType\n",
    "from pyspark.sql import SparkSession\n",
    "import tarfile\n",
    "import os\n",
    "import pyspark.sql.functions as f\n",
    "from pyspark.sql.functions import col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc7f3c24-8009-45bc-9193-bad714227ee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear Spark Session\n",
    "spark = SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2509ce1-7211-4032-9128-55b8d9846255",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funcion para calcular el tamano de un dataframe\n",
    "def get_dataframe_size(df):\n",
    "    # Calculate the size of each column\n",
    "    col_sizes = [f.length(f.col(col_name).cast(\"string\")).alias(col_name) for col_name in df.columns]\n",
    "    # Calculate the total size\n",
    "    total_size = df.select(*col_sizes).groupBy().sum().collect()[0][0]\n",
    "    return total_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa333285-2740-465f-a1f8-be4affb48561",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Peso de review.json\n",
    "file_size = os.path.getsize(\"./data/yelp_dataset.json\")\n",
    "print(\"Tamaño del archivo:\", file_size, \"bytes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a1815d3-dac2-435e-811e-d72f189f12df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carga los archivos extraídos (review.json) en un DataFrame\n",
    "df = spark.read.json(\"./data/yelp_dataset.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "242648f7-493f-44fa-b42a-a2643dd5f0ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcular el tamaño\n",
    "dataframe_size = get_dataframe_size(df)\n",
    "print(\"Tamaño:\", dataframe_size, \"bytes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e084e715-ff27-4f91-8de2-1c89651cd487",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardar el dataframe en parquet\n",
    "df.write.parquet('review.parquet', mode=\"overwrite\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0167f868-8d19-4520-b6f5-6db9186618d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Peso de review.parquet\n",
    "file_size = os.path.getsize(\"review.parquet\")\n",
    "print(\"Tamaño del archivo:\", file_size, \"bytes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "637b96d2-7387-479a-82e9-6fc7f891c5d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inferir el esquema inicial\n",
    "initial_schema = df.schema\n",
    "initial_schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18eb1921-8c1d-4d33-8b25-822dec770536",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir el nuevo esquema\n",
    "optimized_schema = StructType([\n",
    "    StructField(\"review_id\", StringType(), nullable=True),\n",
    "    StructField(\"user_id\", StringType(), nullable=True),\n",
    "    StructField(\"business_id\", StringType(), nullable=True),\n",
    "    StructField(\"stars\", IntegerType(), nullable=True),\n",
    "    StructField(\"date\", DateType(), nullable=True),\n",
    "    StructField(\"text\", StringType(), nullable=True),\n",
    "    StructField(\"useful\", IntegerType(), nullable=True),\n",
    "    StructField(\"funny\", IntegerType(), nullable=True),\n",
    "    StructField(\"cool\", IntegerType(), nullable=True)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddd08a70-ec50-467b-8584-5b47402e2309",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reducido = spark.read.schema(optimized_schema).json(\"./data/ini/yelp_dataset.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b84967e-9517-4372-9499-23426fb94ceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcular el tamaño del df en ram\n",
    "dataframe_size = get_dataframe_size(df_reducido)\n",
    "print(\"Tamaño:\", dataframe_size, \"bytes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e144922c-81a0-4843-b4f6-3092a1ea7d4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Guardar el df_optimized en parquet\n",
    "df_optimized.write.parquet('review_op.parquet', mode=\"overwrite\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caf9897f-8d53-42c3-be3d-184f77c2c6d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Peso del parquet review_op.parquet\n",
    "file_size = os.path.getsize(\"review_op.parquet\")\n",
    "print(\"Tamaño del archivo:\", file_size, \"bytes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0c40006-a7bf-450e-a5fe-1aaee46bc402",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carga los archivos extraídos business.json en un DataFrame\n",
    "df_bus = spark.read.json(\"./data/ini/yelp_dataset.json\")\n",
    "df_bus = df_bus.drop(\"stars\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a25d3fb8-9772-41aa-891a-502019ecc3c8",
   "metadata": {},
   "source": [
    "Se procede a crear el df reducido."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de315172-4d4f-4260-9adb-1343f0299a56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extraer columnas de interés de df_optimized\n",
    "df_reducido_v2 = (\n",
    "    df_reducido\n",
    "     .withColumn(\"year\", f.year(f.col(\"date\")))\n",
    "     .withColumn(\"month\", f.month(f.col(\"date\")))\n",
    "     .select(\"review_id\", \"user_id\", \"business_id\", \"stars\", \"year\", \"month\", \"date\", \"text\", \"useful\", \"funny\", \"cool\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6304d3a5-0523-4037-99e5-2f3d818b464e",
   "metadata": {},
   "outputs": [],
   "source": [
    "schema_df_reducido_v2 = df_reducido_v2.schema\n",
    "schema_df_reducido_v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ac8390a-226a-423e-b29f-e3f7c35279e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Realizar inner join en la columna 'business_id'\n",
    "joined_df = df_bus.join(df_reducido_v2, \"business_id\", \"inner\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efd2bb60",
   "metadata": {},
   "source": [
    "Obtenemos el Parquet particionado por fecha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70eacca4-8c16-41f6-bce3-a2b6fff8fcb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "(joined_df\n",
    "     .write.parquet(\n",
    "         \"op_df_v1\", \n",
    "         mode=\"overwrite\", \n",
    "         partitionBy=[\"year\", \"month\"],\n",
    "         compression=\"gzip\"\n",
    "     )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ef23a37",
   "metadata": {},
   "source": [
    "Parquet particionado por ciudad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de7db559-d78a-42f2-87e2-3060d5056f5c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "(joined_df\n",
    "     .write.parquet(\n",
    "         \"joined_df_v1\", \n",
    "         mode=\"overwrite\", \n",
    "         partitionBy=[\"state\"],\n",
    "         compression=\"gzip\"\n",
    "     )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb6ec543-7de6-40e0-971a-7e84c423da6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parquet particionado por ciudad y fecha\n",
    "(joined_df\n",
    "     .write.parquet(\n",
    "         \"joined_df_v2\", \n",
    "         mode=\"overwrite\", \n",
    "         partitionBy=[\"state\", \"year\", \"month\"],\n",
    "         compression=\"gzip\"\n",
    "     )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de32aee8-3a9c-4b23-86ba-1cb86be7d7be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar el archivo Parquet en un df\n",
    "op_df_v1 = spark.read.parquet(\"./op_df_v1\")\n",
    "\n",
    "# Aplicar el filtro por estado (state) y año (year)\n",
    "filtered_df = op_df_v1.filter((op_df_v1.state == \"CA\") & (op_df_v1.year == \"2016\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a90b0f8e-63d3-4ddf-af59-f5585268ac63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir el nuevo esquema\n",
    "joined_schema = StructType([\n",
    "    StructField(\"review_id\", StringType(), nullable=True),\n",
    "    StructField(\"user_id\", StringType(), nullable=True),\n",
    "    StructField(\"business_id\", StringType(), nullable=True),\n",
    "    StructField(\"stars\", IntegerType(), nullable=True),\n",
    "    StructField(\"date\", DateType(), nullable=True),\n",
    "    StructField(\"year\", IntegerType(), nullable=True),\n",
    "    StructField(\"month\", IntegerType(), nullable=True),\n",
    "    StructField(\"text\", StringType(), nullable=True),\n",
    "    StructField(\"useful\", IntegerType(), nullable=True),\n",
    "    StructField(\"funny\", IntegerType(), nullable=True),\n",
    "    StructField(\"cool\", IntegerType(), nullable=True),\n",
    "    StructField(\"name\", StringType(), True),\n",
    "    StructField(\"address\", StringType(), True),\n",
    "    StructField(\"city\", StringType(), True),\n",
    "    StructField(\"state\", StringType(), True),\n",
    "    StructField(\"postal_code\", StringType(), True),\n",
    "    StructField(\"latitude\", FloatType(), True),\n",
    "    StructField(\"longitude\", FloatType(), True),\n",
    "    StructField(\"review_count\", IntegerType(), True),\n",
    "    StructField(\"is_open\", IntegerType(), True),\n",
    "    StructField(\"attributes\", \n",
    "                StructType([\n",
    "                    StructField(\"RestaurantsTakeOut\", BooleanType(), True),\n",
    "                    StructField(\"BusinessParking\", \n",
    "                                StructType([\n",
    "                                    StructField(\"garage\", BooleanType(), True),\n",
    "                                    StructField(\"street\", BooleanType(), True),\n",
    "                                    StructField(\"validated\", BooleanType(), True),\n",
    "                                    StructField(\"lot\", BooleanType(), True),\n",
    "                                    StructField(\"valet\", BooleanType(), True)\n",
    "                                ]),\n",
    "                                True)\n",
    "                ]),\n",
    "                True),\n",
    "    StructField(\"categories\", ArrayType(StringType()), True),\n",
    "    StructField(\"hours\", \n",
    "                StructType([\n",
    "                    StructField(\"Monday\", StringType(), True),\n",
    "                    StructField(\"Tuesday\", StringType(), True),\n",
    "                    StructField(\"Wednesday\", StringType(), True),\n",
    "                    StructField(\"Thursday\", StringType(), True),\n",
    "                    StructField(\"Friday\", StringType(), True),\n",
    "                    StructField(\"Saturday\", StringType(), True),\n",
    "                    StructField(\"Sunday\", StringType(), True)\n",
    "                ]),\n",
    "                True)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fd33542-2ee8-48ff-b1fe-e5e2e9a0d401",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar el archivo Parquet en un DataFrame\n",
    "joined_df_v1 = spark.read.schema(joined_schema).parquet(\"./joined_df_v1\")\n",
    "# Aplicar el filtro por estado (state) y año (year)\n",
    "filtered_df = joined_df_v1.filter((joined_df_v1.state == \"CA\") & (joined_df_v1.year == \"2016\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8ba285a-6f59-49ba-87f4-3064f80deea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar el archivo Parquet en un DataFrame\n",
    "joined_df_v2 = spark.read.schema(joined_schema).parquet(\"./joined_df_v2\")\n",
    "# Aplicar el filtro por estado (state) y año (year)\n",
    "filtered_df = joined_df_v2.filter((joined_df_v2.state == \"CA\") & (joined_df_v2.year == \"2016\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
